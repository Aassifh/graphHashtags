{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "maskrcnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1mcgSrpZZBRBB12AuAuo6EtUsUZC_cKj8",
      "authorship_tag": "ABX9TyOmU88Rgnp0SqJc5BDo2fR4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aassifh/graphHashtags/blob/master/maskrcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ANU3UlinI_b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e7817d3-1af3-4e6d-85f0-2e58fb9e680a"
      },
      "source": [
        "!pip install imgaug\n",
        "!pip install Cython\n",
        "!pip install pycocotools\n",
        "!pip install kaggle\n",
        "!pip install tensorflow==1.14.0\n",
        "!pip install tensorflow-gpu==1.14.0\n",
        "!pip install keras==2.1.0 "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (0.2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.15.0)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (0.16.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug) (3.2.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.4.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.7.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug) (7.0.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (1.2.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug) (4.4.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.21)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (2.0.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools) (3.2.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools) (0.29.21)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools) (49.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.18.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools) (1.15.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.30.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (49.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-gpu==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.30.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (49.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: keras==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm8TG8RTnYTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttgRcakjuQ4P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f2f8313b-4b86-48d7-e1ea-c2634729b418"
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mask_RCNN'...\n",
            "remote: Enumerating objects: 956, done.\u001b[K\n",
            "remote: Total 956 (delta 0), reused 0 (delta 0), pack-reused 956\u001b[K\n",
            "Receiving objects: 100% (956/956), 116.77 MiB | 11.85 MiB/s, done.\n",
            "Resolving deltas: 100% (565/565), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2hahTgLoCvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "790b8540-863b-41d4-e2c1-0cb9abbf964f"
      },
      "source": [
        "%cd /content/Mask_RCNN/\n",
        "!python3 setup.py install"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mask_RCNN\n",
            "WARNING:root:Fail load requirements file, so using default ones.\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing mask_rcnn.egg-info/PKG-INFO\n",
            "writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n",
            "writing top-level names to mask_rcnn.egg-info/top_level.txt\n",
            "reading manifest template 'MANIFEST.in'\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/mask_rcnn-2.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mask_rcnn-2.1-py3.6.egg\n",
            "Removing /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n",
            "Copying mask_rcnn-2.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "mask-rcnn 2.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n",
            "Processing dependencies for mask-rcnn==2.1\n",
            "Finished processing dependencies for mask-rcnn==2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xhc0psw6oJFl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "dde2ff67-3355-4279-881e-bfd28c571279"
      },
      "source": [
        "!pip show mask-rcnn"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: mask-rcnn\n",
            "Version: 2.1\n",
            "Summary: Mask R-CNN for object detection and instance segmentation\n",
            "Home-page: https://github.com/matterport/Mask_RCNN\n",
            "Author: Matterport\n",
            "Author-email: waleed.abdulla@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n",
            "Requires: \n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOKEPMaRmExQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from xml.etree import ElementTree\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from mrcnn.utils import Dataset\n",
        "from matplotlib import pyplot\n",
        "import skimage.color\n",
        "import skimage.io\n",
        "import skimage.transform\n",
        "import os.path\n",
        "from os import path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4HCmrmIoTRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "77097193-e694-4b1a-88c3-5ac065445342"
      },
      "source": [
        "class BeerDataset(Dataset):\n",
        "\t# load the dataset definitions\n",
        "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
        "\t\t# define one class\n",
        "\t\tself.add_class(\"dataset\", 1, \"beer\")\n",
        "\t\t# define data locations\n",
        "\t\timages_dir = dataset_dir + '/images/'\n",
        "\t\tannotations_dir = dataset_dir + '/annots/'\n",
        "\t\t# find all images\n",
        "\t\tfor filename in listdir(annotations_dir):\n",
        "\t\t\t# extract image id\n",
        "\t\t\timage = filename.split('.')[0]\n",
        "\t\t\timage_id = image.split('img')[1]\n",
        "\t\t\tlabel = image.split('img')[0]\n",
        "\t\t\t\n",
        "\t\t\t\n",
        "\t\t\t# skip bad images\n",
        "\t\t\tif image_id in ['00090']:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t# skip all images after 150 if we are building the train set\n",
        "\t\t\tif is_train and int(image_id) >= 150:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t# skip all images before 150 if we are building the test/val set\n",
        "\t\t\tif not is_train and int(image_id) < 150:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\timg_path = images_dir + label +'img'+ image_id +'.jpg'\n",
        "\t\t\tann_path = annotations_dir + label +'img'+ image_id + '.xml'\n",
        "   \n",
        "\t\t\t# add to dataset\n",
        "\t\t\tself.add_image('dataset', image_id=label +'img'+ image_id, path=img_path, annotation=ann_path)\n",
        "\n",
        "\t# extract bounding boxes from an annotation file\n",
        "\tdef extract_boxes(self, filename):\n",
        "\t\t# load and parse the file\n",
        "\t\ttree = ElementTree.parse(filename)\n",
        "\t\t# get the root of the document\n",
        "\t\troot = tree.getroot()\n",
        "\t\t# extract each bounding box\n",
        "\t\tboxes = list()\n",
        "\t\tfor box in root.findall('.//bndbox'):\n",
        "\t\t\txmin = int(box.find('xmin').text)\n",
        "\t\t\tymin = int(box.find('ymin').text)\n",
        "\t\t\txmax = int(box.find('xmax').text)\n",
        "\t\t\tymax = int(box.find('ymax').text)\n",
        "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
        "\t\t\tboxes.append(coors)\n",
        "\t\t# extract image dimensions\n",
        "\t\twidth = int(root.find('.//size/width').text)\n",
        "\t\theight = int(root.find('.//size/height').text)\n",
        "\t\treturn boxes, width, height\n",
        "\n",
        "\t# load the masks for an image\n",
        "\tdef load_mask(self, image_id):\n",
        "\t\t# get details of image\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\t# define box file location\n",
        "\t\tpath = info['annotation']\n",
        "\t\t# load XML\n",
        "  \n",
        "\t\tboxes, w, h = self.extract_boxes(path)\n",
        "\t\t# create one array for all masks, each on a different channel\n",
        "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\t\t# create masks\n",
        "\t\tclass_ids = list()\n",
        "\t\tfor i in range(len(boxes)):\n",
        "\t\t\tbox = boxes[i]\n",
        "\t\t\trow_s, row_e = box[1], box[3]\n",
        "\t\t\tcol_s, col_e = box[0], box[2]\n",
        "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
        "\t\t\tclass_ids.append(self.class_names.index('beer'))\n",
        "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "\t# load an image reference\n",
        "\tdef image_reference(self, image_id):\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\treturn info['path']\n",
        "\n",
        "\tdef load_image(self, image_id):\n",
        "\t\t\"\"\"Load the specified image and return a [H,W,3] Numpy array.\"\"\"\n",
        "\t\t#print(self.image_info)\n",
        "\t\t# Load image\n",
        "\t\timage = skimage.io.imread(self.image_info[image_id]['path'])\n",
        "\t\t# If grayscale. Convert to RGB for consistency.\n",
        "\t\tif image.ndim != 3:\n",
        "\t\t\timage = skimage.color.gray2rgb(image)\n",
        "\t\t# If has an alpha channel, remove it for consistency\n",
        "\t\tif image.shape[-1] == 4:\n",
        "\t\t\timage = image[..., :3]\n",
        "\t\treturn image"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e87c5b9091fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mBeerDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0;31m# load the dataset definitions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0;31m# define one class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"beer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2vvdjRmpE_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mrcnn.utils import Dataset\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "class Config(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"beer_cfg\"\n",
        "\t# number of classes (background + kangaroo)\n",
        "\tNUM_CLASSES = 1 + 1\n",
        "\t# number of training steps per epoch\n",
        "\tSTEPS_PER_EPOCH = 131\n",
        "\t# updating learning rate\n",
        "\tConfig.LEARNING_RATE = 0.001\n",
        "\tConfig.BATCH_SIZE = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwmYhGHnouYc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1da39a64-54a1-47dc-edb4-4ae765632016"
      },
      "source": [
        "import time \n",
        "start = time.time()\n",
        "# prepare train set\n",
        "train_set = BeerDataset()\n",
        "train_set.load_dataset('/content/drive/My Drive/beer', is_train=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        "# prepare test/val set\n",
        "test_set = BeerDataset()\n",
        "test_set.load_dataset('/content/drive/My Drive/beer', is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))\n",
        "# prepare config\n",
        "config = Config()\n",
        "config.display()\n",
        "\n",
        "# define the model\n",
        "model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
        "# load weights (mscoco) and exclude the output layers\n",
        "model.load_weights('/content/drive/My Drive/models/mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "# train weights (output layers or 'heads')\n",
        "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=20, layers='heads')\n",
        "end = time.time()\n",
        "print(\"Total time : \" + str(end - start))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 171\n",
            "Test: 361\n",
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     2\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 2\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           beer_cfg\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                131\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d30e371ebe51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# define the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaskRCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m# load weights (mscoco) and exclude the output layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/models/mask_rcnn_coco.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mrcnn_class_logits\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mrcnn_bbox_fc\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"mrcnn_bbox\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mrcnn_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mode, config, model_dir)\u001b[0m\n\u001b[1;32m   1835\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_log_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1837\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1839\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, mode, config)\u001b[0m\n\u001b[1;32m   1932\u001b[0m             \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m             \u001b[0;31m# A hack to get around Keras's bad support for constants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1934\u001b[0;31m             \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"anchors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1935\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1936\u001b[0m             \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_anchors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_variable_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_check_variables\u001b[0;34m(self, created_variables, accessed_variables)\u001b[0m\n\u001b[1;32m    929\u001b[0m           Variables.'''\n\u001b[1;32m    930\u001b[0m       ).format(name=self.name, variable_str=variable_str)\n\u001b[0;32m--> 931\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     untracked_used_vars = [\n",
            "\u001b[0;31mValueError\u001b[0m: \nThe following Variables were created within a Lambda layer (anchors)\nbut are not tracked by said layer:\n  <tf.Variable 'anchors/Variable:0' shape=(2, 261888, 4) dtype=float32>\nThe layer cannot safely ensure proper Variable reuse across multiple\ncalls, and consquently this behavior is disallowed for safety. Lambda\nlayers are not well suited to stateful computation; instead, writing a\nsubclassed Layer is the recommend way to define layers with\nVariables."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anjfRRF5oWJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mrcnn.utils import compute_ap\n",
        "from mrcnn.model import load_image_gt\n",
        "from mrcnn.model import mold_image\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "\n",
        "class Config(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"beer_cfg\"\n",
        "\t# number of classes (background + kangaroo)\n",
        "\tNUM_CLASSES = 1 + 1\n",
        "\t# number of training steps per epoch\n",
        "\tSTEPS_PER_EPOCH = 131\n",
        "\t# updating learning rate\n",
        "\tConfig.LEARNING_RATE = 0.001\n",
        "  # simplify GPU config\n",
        "\tGPU_COUNT = 1\n",
        "\tIMAGES_PER_GPU = 1\n",
        "\n",
        "# calculate the mAP for a model on a given dataset\n",
        "def evaluate_model(dataset, model, cfg):\n",
        "\tAPs = list()\n",
        "\tfor image_id in dataset.image_ids:\n",
        "\t\t# load image, bounding boxes and masks for the image id\n",
        "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "\t\t# convert pixel values (e.g. center)\n",
        "\t\tscaled_image = mold_image(image, cfg)\n",
        "\t\t# convert image into one sample\n",
        "\t\tsample = expand_dims(scaled_image, 0)\n",
        "\t\t# make prediction\n",
        "\t\tyhat = model.detect(sample, verbose=0)\n",
        "\t\t# extract results for first sample\n",
        "\t\tr = yhat[0]\n",
        "\t\t# calculate statistics, including AP\n",
        "\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "\t\t# store\n",
        "\t\tAPs.append(AP)\n",
        "\t# calculate the mean AP across all images\n",
        "\tmAP = mean(APs)\n",
        "\treturn mAP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpVfzoQ0oVzv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "39eff738-5500-43b8-d06d-b7a4bb6ed462"
      },
      "source": [
        "cfg = Config()\n",
        "\n",
        "# define the model\n",
        "model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
        "# load model weights\n",
        "model.load_weights('/content/Mask_RCNN/beer_cfg20200801T1129/mask_rcnn_beer_cfg_0020.h5', by_name=True)\n",
        "# evaluate model on training dataset\n",
        "train_mAP = evaluate_model(train_set, model, cfg)\n",
        "print(\"Train mAP: %.3f\" % train_mAP)\n",
        "# evaluate model on test dataset\n",
        "test_mAP = evaluate_model(test_set, model, cfg)\n",
        "print(\"Test mAP: %.3f\" % test_mAP)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Re-starting from epoch 20\n",
            "Train mAP: 0.879\n",
            "Test mAP: 0.530\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc8jnQgQo3AA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "# plot a number of photos with ground truth and predictions\n",
        "def plot_actual_vs_predicted(dataset, model, cfg, n_images=5):\n",
        "\t# load image and mask\n",
        "\tfor i in range(n_images):\n",
        "\t\t# load the image and mask\n",
        "\t\timage = dataset.load_image(i)\n",
        "\t\tmask, _ = dataset.load_mask(i)\n",
        "\t\t# convert pixel values (e.g. center)\n",
        "\t\tscaled_image = mold_image(image, cfg)\n",
        "\t\t# convert image into one sample\n",
        "\t\tsample = expand_dims(scaled_image, 0)\n",
        "\t\t# make prediction\n",
        "\t\tyhat = model.detect(sample, verbose=0)[0]\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(n_images, 2, i*2+1)\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(image)\n",
        "\t\tpyplot.title('Actual')\n",
        "\t\t# plot masks\n",
        "\t\tfor j in range(mask.shape[2]):\n",
        "\t\t\tpyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
        "\t\t# get the context for drawing boxes\n",
        "\t\tpyplot.subplot(n_images, 2, i*2+2)\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(image)\n",
        "\t\tpyplot.title('Predicted')\n",
        "\t\tax = pyplot.gca()\n",
        "\t\t# plot each box\n",
        "\t\tfor box in yhat['rois']:\n",
        "\t\t\t# get coordinates\n",
        "\t\t\ty1, x1, y2, x2 = box\n",
        "\t\t\t# calculate width and height of the box\n",
        "\t\t\twidth, height = x2 - x1, y2 - y1\n",
        "\t\t\t# create the shape\n",
        "\t\t\trect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
        "\t\t\t# draw the box\n",
        "\t\t\tax.add_patch(rect)\n",
        "\t# save plot\n",
        "\tpyplot.savefig('out.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-apmvyGKD3xC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "4544202c-50ae-46e4-b364-46551816d60e"
      },
      "source": [
        "# define the model\n",
        "model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
        "# load model weights\n",
        "model_path = '/content/Mask_RCNN/beer_cfg20200801T1129/mask_rcnn_beer_cfg_0020.h5'\n",
        "model.load_weights(model_path, by_name=True)\n",
        "# plot predictions for train dataset\n",
        "plot_actual_vs_predicted(train_set, model, cfg)\n",
        "# plot predictions for test dataset\n",
        "plot_actual_vs_predicted(test_set, model, cfg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Re-starting from epoch 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-d41486c66634>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# plot predictions for train dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplot_actual_vs_predicted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# plot predictions for test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplot_actual_vs_predicted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-4b3bcaa73d12>\u001b[0m in \u001b[0;36mplot_actual_vs_predicted\u001b[0;34m(dataset, model, cfg, n_images)\u001b[0m\n\u001b[1;32m     33\u001b[0m                         \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                         \u001b[0;31m# create the shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                         \u001b[0mrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                         \u001b[0;31m# draw the box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_patch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Rectangle' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}